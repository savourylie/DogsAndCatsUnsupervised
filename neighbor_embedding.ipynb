{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from glob import glob\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from dstorch.utils import random_weight_init\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# USE_GPUS = '1'\n",
    "USE_GPUS = '0, 1, 2, 3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = USE_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/train/'\n",
    "val_path = './data/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsCatsDataset(Dataset):\n",
    "    def __init__(self, data_path, category=None, resize=500, input_size=224, \n",
    "                 crop_ratio=0.25, degenerate=True, color_drop=True, swap_labels_flag=True, \n",
    "                 transform=None):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.category = category\n",
    "        self.resize = resize\n",
    "        self.input_size = input_size\n",
    "        self.crop_ratio = crop_ratio\n",
    "        self.degenerate = degenerate\n",
    "        self.color_drop = color_drop\n",
    "        self.swap_labels_flag = swap_labels_flag\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        self.dog_filename_list = glob(self.data_path + 'dogs/*.jpg')\n",
    "        self.cat_filename_list = glob(self.data_path + 'cats/*.jpg')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        dog_filename, cat_filename = self.dog_filename_list[index], self.cat_filename_list[index]\n",
    "        \n",
    "        dog_img, cat_img = cv2.imread(dog_filename), cv2.imread(cat_filename)\n",
    "        dog_img, cat_img = cv2.cvtColor(dog_img, cv2.COLOR_BGR2RGB), cv2.cvtColor(cat_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.category is not None:\n",
    "            img, label = dog_img, 1 if self.category == 'dog' else cat_img, 0\n",
    "        \n",
    "        else:\n",
    "            choice = np.random.choice([0, 1])\n",
    "            \n",
    "            img = dog_img if choice else cat_img\n",
    "            label = choice\n",
    "           \n",
    "        # Crop largest square image\n",
    "        img = self.crop_center(img, 1)        \n",
    "        # Resize image\n",
    "        img = cv2.resize(img, (self.resize, self.resize))\n",
    "        # Get center image\n",
    "        img_center = self.crop_center(img, self.crop_ratio)\n",
    "        # Get context image and idx\n",
    "        img_context, idx = self.get_context_img(img)\n",
    "        # Resize to 224\n",
    "        img_center = cv2.resize(img_center, (self.input_size, self.input_size))\n",
    "        img_context = cv2.resize(img_context, (self.input_size, self.input_size))\n",
    "        \n",
    "        if self.degenerate:\n",
    "            degen_choice = np.random.choice([0, 1], p=[0.9, 0.1])\n",
    "            \n",
    "            if degen_choice:\n",
    "                img_center, img_context = self.degenerate_img(img_center), self.degenerate_img(img_context)\n",
    "            \n",
    "        if self.color_drop:\n",
    "            img_center, img_context = self.color_drop_img(img_center), self.color_drop_img(img_context)\n",
    "            \n",
    "        if self.swap_labels_flag:\n",
    "            swap_choice = np.random.choice([0, 1], p=[0.9, 0.1])\n",
    "\n",
    "            if swap_choice:\n",
    "                img_center, img_context, idx = self.swap_labels(img_center, img_context, idx)\n",
    "            \n",
    "        # Convert to torch tensor\n",
    "        img_center = torch.from_numpy(np.rollaxis(img_center / 255, 2).copy()).float()\n",
    "        img_context = torch.from_numpy(np.rollaxis(img_context / 255, 2).copy()).float()\n",
    "        \n",
    "        # Stats of the training data\n",
    "        center_mean = [0.4918, 0.4464, 0.4091]\n",
    "        context_mean = [0.4868, 0.4494, 0.4100]\n",
    "        \n",
    "        center_std = [0.2016, 0.1920, 0.1911]\n",
    "        context_std = [0.1939, 0.1853, 0.1876] \n",
    "\n",
    "        # Normalization\n",
    "        img_center -= torch.tensor(center_mean).view(3, 1, 1)\n",
    "        img_center /= torch.tensor(center_std).view(3, 1, 1)\n",
    "        \n",
    "        img_context -= torch.tensor(context_mean).view(3, 1, 1)\n",
    "        img_context /= torch.tensor(context_std).view(3, 1, 1)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_center = self.transform(img_center)\n",
    "            img_context = self.transform(img_context)\n",
    "            \n",
    "        return (img_center, img_context), idx, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.dog_filename_list)\n",
    "    \n",
    "    @staticmethod\n",
    "    def swap_labels(img_center, img_context, idx):\n",
    "        _, idx = divmod(idx - 4, 8)\n",
    "        \n",
    "        return img_context, img_center, idx\n",
    "    \n",
    "    @staticmethod\n",
    "    def degenerate_img(img, low=0.1):\n",
    "        img = img.copy()\n",
    "        \n",
    "        input_size = img.shape[0]\n",
    "\n",
    "        p = np.random.uniform(low=low, size=1)        \n",
    "        degen_size = int(p * input_size)\n",
    "\n",
    "        img = cv2.resize(img, (degen_size, degen_size))\n",
    "        img = cv2.resize(img, (input_size, input_size))\n",
    "\n",
    "        return img\n",
    "        \n",
    "    @staticmethod\n",
    "    def color_drop_img(img, std=0.01):\n",
    "        img = img.copy()\n",
    "\n",
    "        color_set = {0, 1, 2}\n",
    "        drop_set = set(np.random.choice((0, 1, 2), size=2, replace=False).tolist())\n",
    "\n",
    "        idx_remained = next(iter(color_set - drop_set))\n",
    "\n",
    "        color_std = img[:, :, idx_remained].std() * std\n",
    "\n",
    "        for color_idx in drop_set:\n",
    "            mean = img[:, :, color_idx].mean()\n",
    "            channel_data = np.random.normal(mean, color_std, size=[img.shape[0], img.shape[1]])\n",
    "            img[:, :, color_idx] = channel_data\n",
    "\n",
    "        return img\n",
    "\n",
    "    @staticmethod\n",
    "    def crop_center(img, crop_ratio):       \n",
    "        x, y, _ = img.shape\n",
    "\n",
    "        max_size = min(x, y)\n",
    "        max_size = int(max_size * crop_ratio)\n",
    "\n",
    "        x_start = max(x // 2 - (max_size // 2), 0)\n",
    "        y_start = max(y // 2 - (max_size // 2), 0)\n",
    "\n",
    "        x_end = x_start + max_size\n",
    "        y_end = y_start + max_size\n",
    "\n",
    "        img = img[x_start:x_end, y_start:y_end, :]\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def get_context_img(self, img):\n",
    "        x, y, _ = img.shape\n",
    "\n",
    "        max_size = min(x, y)\n",
    "        max_size = int(max_size * self.crop_ratio)\n",
    "        gap_size = max_size // 4\n",
    "        \n",
    "        x_center, y_center = x // 2, y // 2\n",
    "        \n",
    "        candidate_dict = {\n",
    "                          0: (-1, -1),\n",
    "                          1: (-1, 0),\n",
    "                          2: (-1, 1),\n",
    "                          3: (0, 1),\n",
    "                          4: (1, 1),\n",
    "                          5: (1, 0),\n",
    "                          6: (1, -1),\n",
    "                          7: (0, -1)\n",
    "                         }\n",
    "        \n",
    "        idx = int(np.random.choice(range(len(candidate_dict))))\n",
    "        context_factor = 150 + int(np.random.normal(0, 7))\n",
    "        \n",
    "        x_compare = x_center + context_factor * candidate_dict[idx][0]    \n",
    "        y_compare = y_center + context_factor * candidate_dict[idx][1]\n",
    "        \n",
    "        x_compare_start, y_compare_start = x_compare - max_size // 2, y_compare - max_size // 2\n",
    "        x_compare_end, y_compare_end = x_compare_start + max_size, y_compare_start + max_size\n",
    "        \n",
    "        return img[x_compare_start:x_compare_end, y_compare_start:y_compare_end, :], idx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_list = glob(train_path + 'dogs/*.jpg') + glob(train_path + 'cats/*.jpg')\n",
    "\n",
    "# bgr2rgb = partial(cv2.cvtColor, code=cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# img_list = list(map(bgr2rgb, [cv2.imread(path) for path in tqdm_notebook(data_path_list)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_list, col_list = [], []\n",
    "\n",
    "# for img in img_list:\n",
    "#     num_rows, num_cols, num_channels = img.shape\n",
    "    \n",
    "#     row_list.append(num_rows)\n",
    "#     col_list.append(num_cols)\n",
    "        \n",
    "# print(\"Rows: Max: {}, Min: {}, Median: {}\".format(np.max(row_list), np.min(row_list), \n",
    "#                                                   np.median(row_list)))\n",
    "# print(\"Cols: Max: {}, Min: {}, Median: {}\".format(np.max(col_list), np.min(col_list), \n",
    "#                                                   np.median(col_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 * len(USE_GPUS.split(','))\n",
    "\n",
    "kwargs = {'num_workers': len(USE_GPUS.split(',')) * 4, 'pin_memory': False} \\\n",
    "          if torch.cuda.is_available() else {}\n",
    "\n",
    "# mean_tuple = (0.4901, 0.4546, 0.4159)\n",
    "# std_tuple = (0.1171, 0.1086, 0.1122)\n",
    "\n",
    "# transform_train = transforms.Compose([\n",
    "# #                                       transforms.RandomHorizontalFlip(),\n",
    "#                                       transforms.Normalize(mean_tuple, std_tuple)\n",
    "#                                      ])\n",
    "\n",
    "# transform_val = transforms.Compose([\n",
    "#                                      transforms.Normalize(mean_tuple, std_tuple)\n",
    "#                                     ])\n",
    "\n",
    "training_set = DogsCatsDataset(train_path)\n",
    "training_no_aug_set = DogsCatsDataset(train_path, degenerate=False, \n",
    "                                      color_drop=False, swap_labels_flag=False)\n",
    "validation_set = DogsCatsDataset(val_path, degenerate=False, \n",
    "                                 color_drop=False, swap_labels_flag=False)\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "train_no_aug_loader = DataLoader(training_set, batch_size=batch_size, shuffle=False,**kwargs)\n",
    "valid_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_data_stats(data_loader, dtype='image', repeat=20):\n",
    "#     batch_size = data_loader.batch_size\n",
    "\n",
    "#     sample_size = 0\n",
    "    \n",
    "#     center_mean_list = []\n",
    "#     context_mean_list = []\n",
    "    \n",
    "#     for _ in tqdm_notebook(range(repeat)):\n",
    "#         for (img_center, img_context), idx, label in tqdm_notebook(data_loader):\n",
    "#             if torch.cuda.is_available():\n",
    "#                 img_center, img_context = img_center.cuda(non_blocking=True), img_context.cuda(non_blocking=True)\n",
    "                \n",
    "#             img_center = img_center.view(img_center.size(0), img_center.size(1), -1)\n",
    "#             img_context = img_context.view(img_context.size(0), img_context.size(1), -1)\n",
    "            \n",
    "#             center_mean_list.append(img_center.mean(2).mean(0))\n",
    "#             context_mean_list.append(img_context.mean(2).mean(0))\n",
    "\n",
    "#             sample_size += img_center.shape[0] \n",
    "        \n",
    "#     center_mean = torch.stack(center_mean_list).mean(dim=0)\n",
    "#     context_mean = torch.stack(context_mean_list).mean(dim=0)\n",
    "    \n",
    "#     center_se = torch.stack(center_mean_list).std(dim=0)\n",
    "#     context_se = torch.stack(context_mean_list).std(dim=0)\n",
    "    \n",
    "#     center_std = center_se * torch.sqrt(torch.tensor(float(batch_size)))\n",
    "#     context_std = context_se * torch.sqrt(torch.tensor(float(batch_size)))\n",
    "    \n",
    "\n",
    "#     print(\"=============================\")\n",
    "#     print(\"Dataset size: {}\".format(sample_size))\n",
    "#     print(\"Batch size: {}\".format(batch_size))\n",
    "    \n",
    "#     print(\"Center Mean: {}\".format(center_mean))\n",
    "#     print(\"Context Mean: {}\".format(context_mean))\n",
    "    \n",
    "#     print(\"Center STD: {}\".format(center_std))\n",
    "#     print(\"ContextSTD: {}\".format(context_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_data_stats(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextNet(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "#         self.resnet = nn.Sequential(*list(models.resnet50(pretrained=pretrained).children())[:-1])\n",
    "        self.resnet = nn.Sequential(*list(models.resnet152(pretrained=pretrained).children())[:-1])\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                                        nn.Linear(2048, 2048),\n",
    "                                        nn.Dropout(0.5),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Linear(2048, 8),\n",
    "                                        nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "               \n",
    "    def forward(self, x):\n",
    "        img_center, img_compare = x\n",
    "        \n",
    "        img_center = self.resnet(img_center)\n",
    "        img_compare = self.resnet(img_compare)\n",
    "        \n",
    "        img_flat_size = img_center.size(1) * img_center.size(2) * img_center.size(3)\n",
    "        \n",
    "        img_center = img_center.view(-1, img_flat_size)\n",
    "        img_compare = img_compare.view(-1, img_flat_size)\n",
    "        \n",
    "        img = img_center + img_compare\n",
    "        \n",
    "        output = self.classifier(img)\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContextNet(False)\n",
    "random_weight_init(model)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, It: 0, Loss: 5.9142\n",
      "Epoch: 0, It: 20, Loss: 2.5943\n"
     ]
    }
   ],
   "source": [
    "loss_list, loss_test_list = [], []\n",
    "\n",
    "epochs = 5000\n",
    "lr = 0.001\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_temp_list, loss_test_temp_list = [], []\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "        if not next(model.parameters()).is_cuda:\n",
    "            raise TypeError(\"model.cuda() is not working!\")\n",
    "\n",
    "    else:\n",
    "        model = model.cpu()  \n",
    "\n",
    "    for batch_idx, (data, idx, _) in enumerate(train_loader):\n",
    "        img_center, img_context = data\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            img_center, img_context = img_center.cuda(non_blocking=True), img_context.cuda(non_blocking=True)\n",
    "            idx = idx.cuda(non_blocking=True)\n",
    "        else:\n",
    "            img_center, img_context, idx = img_center.cpu(), img_context.cpu(), idx.cpu()\n",
    "\n",
    "        img_center, img_context, idx = Variable(img_center), Variable(img_context), Variable(idx)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model((img_center, img_context))\n",
    "        \n",
    "        loss = loss_func(output, idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\"Epoch: {0}, It: {1}, Loss: {2:.4f}\".format(epoch, batch_idx, loss))\n",
    "     \n",
    "    model.eval()\n",
    "        \n",
    "    num_rows_train = 0\n",
    "    correct_train = 0\n",
    "    \n",
    "    # Training set\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, idx, _) in enumerate(train_no_aug_loader):\n",
    "            img_center, img_context = data\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                img_center, img_context = img_center.cuda(non_blocking=True), img_context.cuda(non_blocking=True)\n",
    "                idx = idx.cuda(non_blocking=True)\n",
    "            else:\n",
    "                img_center, img_context = img_center.cpu(), img_context.cpu(), idx.cpu()\n",
    "\n",
    "            img_center, img_context, idx = Variable(img_center), Variable(img_context), Variable(idx)\n",
    "            num_rows_train += img_center.size(0)\n",
    "            \n",
    "            output = model((img_center, img_context))\n",
    "            loss = loss_func(output, idx)\n",
    "            \n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct_train += pred.eq(idx.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            loss_temp_list.append(loss.detach().item())\n",
    "     \n",
    "    num_rows = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, idx, _) in enumerate(valid_loader):\n",
    "            img_center, img_context = data\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                img_center, img_context = img_center.cuda(non_blocking=True), img_context.cuda(non_blocking=True)\n",
    "                idx = idx.cuda(non_blocking=True)\n",
    "            else:\n",
    "                img_center, img_context = img_center.cpu(), img_context.cpu(), idx.cpu()\n",
    "\n",
    "            img_center, img_context, idx = Variable(img_center), Variable(img_context), Variable(idx)\n",
    "            num_rows += img_center.size(0)\n",
    "            \n",
    "            output = model((img_center, img_context))\n",
    "            loss_test = loss_func(output, idx)\n",
    "            \n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(idx.data.view_as(pred)).cpu().sum()\n",
    "            \n",
    "            loss_test_temp_list.append(loss_test.detach().item())\n",
    "            \n",
    "    loss_mean, loss_test_mean = np.mean(loss_temp_list), np.mean(loss_test_temp_list)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = 'models/model_{}.pth'.format(epoch)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(\"Model saved at {}\".format(model_path))\n",
    "    \n",
    "    print(\"=====================================================================\")\n",
    "    print(\"Training loss: {:.4f} Training acc: {:.4f}%\".format(loss_mean, (100. * correct_train.item()) / num_rows_train))\n",
    "    print(\"Test loss: {0:.4f}, Test acc: {1:.4f}%\".format(np.mean(loss_test_mean), (100. * correct.item()) / num_rows))\n",
    "    print(\"Epoch took {} seconds.\".format(time.time() - epoch_start_time))\n",
    "    print(\"=====================================================================\")\n",
    "    \n",
    "    loss_list.append(loss_mean)\n",
    "    loss_test_list.append(loss_test_mean)\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Draw for training loss\n",
    "    plt.plot(range(len(loss_list)), list(map(np.log, loss_list)), label=\"Training\")\n",
    "    # Draw for test loss\n",
    "    plt.plot(range(len(loss_test_list)), list(map(np.log, loss_test_list)), label=\"Test\")\n",
    "    # Side info\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "print(\"Training took {} seconds\\n\".format(round(time.time() - start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
